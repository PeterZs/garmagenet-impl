{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89bd0596-7ad4-4651-87b8-b58ff3c26439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "PROJ_ROOT = '/data/lry/code/style3d_gen'\n",
    "\n",
    "sys.path.append(PROJ_ROOT)\n",
    "sys.path.append(os.path.join(PROJ_ROOT, 'src'))\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f8f126",
   "metadata": {},
   "source": [
    "# Test VAE (decoder only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0144d493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from network import AutoencoderKLFastDecode, AutoencoderKLFastEncode\n",
    "\n",
    "import torch\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "cache_fp = '/data/lry/code/style3d_gen/log/stylexd_vae_surf_256_xyz_uv_mask_unet6/cache/epoch_1800/surfz_train.pkl'\n",
    "with open(cache_fp, 'rb') as f: data_cache = pickle.load(f)\n",
    "print(data_cache.keys(), len(data_cache['item_idx']))\n",
    "\n",
    "ckpt_fp = '/data/lry/code/style3d_gen/log/stylexd_vae_surf_256_xyz_uv_mask_unet6/ckpts/epoch_1800.pt'\n",
    "block_dims = [16,32,32,64,64,128]\n",
    "sample_size = 256\n",
    "latent_channels = 8\n",
    "latent_size = sample_size // 2**(len(block_dims)-1)\n",
    "print('*** latent size: ', latent_size)\n",
    "\n",
    "surf_vae_decoder = AutoencoderKLFastDecode( \n",
    "                                    in_channels=6,\n",
    "                                    out_channels=6,\n",
    "                                    down_block_types=['DownEncoderBlock2D']*len(block_dims),\n",
    "                                    up_block_types=['UpDecoderBlock2D']*len(block_dims),\n",
    "                                    block_out_channels=block_dims,\n",
    "                                    layers_per_block=2,\n",
    "                                    act_fn='silu',\n",
    "                                    latent_channels=latent_channels,\n",
    "                                    norm_num_groups=8,\n",
    "                                    sample_size=sample_size\n",
    "                                    )\n",
    "surf_vae_decoder.load_state_dict(torch.load(ckpt_fp), strict=False)\n",
    "\n",
    "\n",
    "sample_data_idx = random.randint(0, len(data_cache['item_idx']) - 1)\n",
    "start_idx, end_idx = data_cache['item_idx'][sample_data_idx]\n",
    "\n",
    "print(sample_data_idx, start_idx, end_idx)\n",
    "\n",
    "surf_pos = data_cache['surf_pos'][start_idx:end_idx]\n",
    "surf_latent = data_cache['latent'][start_idx:end_idx]\n",
    "surf_cls = data_cache['surf_cls'][start_idx:end_idx]\n",
    "caption = data_cache['caption'][sample_data_idx]\n",
    "\n",
    "print(surf_pos.shape, surf_latent.shape, surf_cls.shape, caption)\n",
    "\n",
    "print('*** surf_latent: ', surf_latent.shape, surf_latent.min(), surf_latent.max(), surf_latent.mean(), surf_latent.std())\n",
    "with torch.no_grad():\n",
    "    decoded_surf_pos = surf_vae_decoder(surf_latent.view(-1, latent_channels, latent_size, latent_size))\n",
    "print('*** decoded: ', decoded_surf_pos.shape, decoded_surf_pos.min(), decoded_surf_pos.max())\n",
    "\n",
    "pred_img = make_grid(decoded_surf_pos, nrow=8, normalize=True, value_range=(-1,1))\n",
    "print(pred_img.shape, pred_img.min(), pred_img.max())\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, figsize=(40, 40))\n",
    "ax[0].imshow(pred_img[:3, ...].permute(1, 2, 0).cpu().numpy())\n",
    "ax[1].imshow(pred_img[3:, ...].permute(1, 2, 0).cpu().numpy())\n",
    "ax[2].imshow(pred_img[-1:, ...].permute(1, 2, 0).cpu().numpy())\n",
    "\n",
    "ax[0].set_title('Geometry Images')\n",
    "ax[1].set_title('UV Images')\n",
    "ax[2].set_title('Mask Images')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70e6740",
   "metadata": {},
   "source": [
    "# Test VAE with Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489a479b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from network import AutoencoderKLFastDecode, AutoencoderKLFastEncode\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "_DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "ckpt_fp = '/data/lry/code/style3d_gen/log/stylexd_vae_surf_256_xyz_uv_mask_unet6/ckpts/epoch_1800.pt'\n",
    "block_dims = [16,32,32,64,64,128]\n",
    "sample_size = 256\n",
    "latent_channels = 8\n",
    "latent_size = sample_size // 2**(len(block_dims)-1)\n",
    "print('*** latent size: ', latent_size, ' latent_channels: ', latent_channels)\n",
    "\n",
    "################# Inintialize the encoder and decoder #################\n",
    "surf_vae_encoder = AutoencoderKLFastEncode( \n",
    "                                    in_channels=6,\n",
    "                                    out_channels=6,\n",
    "                                    down_block_types=['DownEncoderBlock2D']*len(block_dims),\n",
    "                                    up_block_types=['UpDecoderBlock2D']*len(block_dims),\n",
    "                                    block_out_channels=block_dims,\n",
    "                                    layers_per_block=2,\n",
    "                                    act_fn='silu',\n",
    "                                    latent_channels=latent_channels,\n",
    "                                    norm_num_groups=8,\n",
    "                                    sample_size=sample_size\n",
    "                                    )\n",
    "surf_vae_encoder.load_state_dict(torch.load(ckpt_fp), strict=False)\n",
    "surf_vae_encoder.eval().to(_DEVICE)\n",
    "\n",
    "\n",
    "surf_vae_decoder = AutoencoderKLFastDecode( \n",
    "                                    in_channels=6,\n",
    "                                    out_channels=6,\n",
    "                                    down_block_types=['DownEncoderBlock2D']*len(block_dims),\n",
    "                                    up_block_types=['UpDecoderBlock2D']*len(block_dims),\n",
    "                                    block_out_channels=block_dims,\n",
    "                                    layers_per_block=2,\n",
    "                                    act_fn='silu',\n",
    "                                    latent_channels=latent_channels,\n",
    "                                    norm_num_groups=8,\n",
    "                                    sample_size=sample_size\n",
    "                                    )\n",
    "surf_vae_decoder.load_state_dict(torch.load(ckpt_fp), strict=False)\n",
    "surf_vae_decoder.eval().to(_DEVICE)\n",
    "########################################################################\n",
    "\n",
    "\n",
    "data_root = '/data/AIGP/brep_reso_256_edge_snap_with_caption'\n",
    "data_fp = random.choice(glob(os.path.join(data_root, '*.pkl')))\n",
    "print(data_fp)\n",
    "\n",
    "with open(data_fp, 'rb') as f: data = pickle.load(f)\n",
    "surf_ncs = torch.FloatTensor(np.concatenate([\n",
    "    data['surf_ncs'].astype(np.float32),\n",
    "    data['surf_uv_ncs'].astype(np.float32),\n",
    "    data['surf_mask'].astype(np.float32)*2.0-1.0\n",
    "], axis=-1)).to(_DEVICE)\n",
    "\n",
    "print('*** caption: ', data['caption'])\n",
    "\n",
    "with torch.no_grad():\n",
    "    latent = surf_vae_encoder(surf_ncs.permute(0, 3, 1, 2)).flatten(start_dim=1)\n",
    "    print('*** latent: ', latent.shape, latent.min(), latent.max(), latent.mean(), latent.std())\n",
    "    decoded_surf_ncs = surf_vae_decoder(latent.view(-1, latent_channels, latent_size, latent_size))\n",
    "    print('*** decoded: ', decoded_surf_ncs.shape, decoded_surf_ncs.min(), decoded_surf_ncs.max())\n",
    "\n",
    "pred_img = make_grid(decoded_surf_ncs, nrow=8, normalize=True, value_range=(-1,1))\n",
    "print(pred_img.shape, pred_img.min(), pred_img.max())\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, figsize=(40, 40))\n",
    "ax[0].imshow(pred_img[:3, ...].permute(1, 2, 0).cpu().numpy())\n",
    "ax[1].imshow(pred_img[3:, ...].permute(1, 2, 0).cpu().numpy())\n",
    "ax[2].imshow(pred_img[-1:, ...].permute(1, 2, 0).cpu().numpy())\n",
    "\n",
    "ax[0].set_title('Geometry Images')\n",
    "ax[1].set_title('UV Images')\n",
    "ax[2].set_title('Mask Images')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba614b9a",
   "metadata": {},
   "source": [
    "# Test VAE && SurfZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f79facdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "\n",
    "import torch\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import to_hex\n",
    "\n",
    "from network import AutoencoderKLFastDecode, SurfZNet\n",
    "from diffusers import DDPMScheduler, PNDMScheduler\n",
    "from utils import randn_tensor\n",
    "from vis import draw_bbox_geometry\n",
    "\n",
    "\n",
    "\n",
    "def _denormalize_pts(pts, bbox):    \n",
    "    pos_dim =  pts.shape[-1]\n",
    "    bbox_min = bbox[..., :pos_dim][:, None, ...]\n",
    "    bbox_max = bbox[..., pos_dim:][:, None, ...]\n",
    "    bbox_scale = np.max(bbox_max - bbox_min, axis=-1, keepdims=True) * 0.5\n",
    "    bbox_offset = (bbox_max + bbox_min) / 2.0\n",
    "    return pts * bbox_scale + bbox_offset\n",
    "\n",
    "\n",
    "vae_model_fp = '/data/lry/code/style3d_gen/log/stylexd_vae_surf_256_xyz_uv_mask_unet6_latent_1/ckpts/vae_e550.pt'\n",
    "surfz_model_fp = '/data/lry/code/style3d_gen/log/stylexd_surfz_xyzuv_mask_latent1_mode/ckpts/surfz_e210000.pt'\n",
    "\n",
    "output_dir = '/data/lry/code/style3d_gen/generated/surfz_e150000'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ckpt_fp = '/data/lry/code/dy/checkpoint/6G/ldm/surfz10200.pt'\n",
    "block_dims = [16,32,32,64,64,128]\n",
    "sample_size = 256\n",
    "latent_size = sample_size//(2**(len(block_dims)-1))\n",
    "latent_channels = 1\n",
    "\n",
    "surf_vae = AutoencoderKLFastDecode( in_channels=6,\n",
    "                                    out_channels=6,\n",
    "                                    down_block_types=['DownEncoderBlock2D']*len(block_dims),\n",
    "                                    up_block_types=['UpDecoderBlock2D']*len(block_dims),\n",
    "                                    block_out_channels=block_dims,\n",
    "                                    layers_per_block=2,\n",
    "                                    act_fn='silu',\n",
    "                                    latent_channels=latent_channels,\n",
    "                                    norm_num_groups=8,\n",
    "                                    sample_size=sample_size\n",
    "                                    )\n",
    "surf_vae.load_state_dict(torch.load(vae_model_fp), strict=False)\n",
    "surf_vae.to('cuda').eval()\n",
    "\n",
    "pndm_scheduler = PNDMScheduler(\n",
    "    num_train_timesteps=1000,\n",
    "    beta_schedule='linear',\n",
    "    prediction_type='epsilon',\n",
    "    beta_start=0.0001,\n",
    "    beta_end=0.02,\n",
    ")\n",
    "\n",
    "ddpm_scheduler = DDPMScheduler(\n",
    "    num_train_timesteps=1000,\n",
    "    beta_schedule='linear',\n",
    "    prediction_type='epsilon',\n",
    "    beta_start=0.0001,\n",
    "    beta_end=0.02,\n",
    "    clip_sample=False,\n",
    ")\n",
    "\n",
    "# Load SurfZ Net\n",
    "surfz_model = SurfZNet(\n",
    "    p_dim=10, \n",
    "    z_dim=latent_size**2*latent_channels, \n",
    "    num_heads=12, \n",
    "    num_cf=-1\n",
    "    )\n",
    "surfz_model.load_state_dict(torch.load(surfz_model_fp)['model_state_dict'])\n",
    "surfz_model.to('cuda').eval()\n",
    "\n",
    "def inference_one(surf_pos, surf_cls=None, caption='', output_fp='', vis=False):\n",
    "    n_surfs, n_pads = surf_pos.shape[0], 32-surf_pos.shape[0]\n",
    "    # # pad zero\n",
    "    pad_idx = torch.randperm(n_surfs)\n",
    "    _surf_mask = torch.cat([\n",
    "        torch.zeros(n_surfs, dtype=bool), torch.ones(n_pads, dtype=bool)\n",
    "    ], dim=0)[None, ...]\n",
    "    _surf_pos = torch.cat([\n",
    "        surf_pos[pad_idx, ...], torch.zeros((n_pads, *surf_pos.shape[1:]), dtype=surf_pos.dtype, device=surf_pos.device)\n",
    "    ], dim=0)[None, ...]\n",
    "\n",
    "    # Diffusion Generation\n",
    "    _surf_z = randn_tensor((1, 32, latent_channels*latent_size*latent_size), device='cuda')\n",
    "    ddpm_scheduler.set_timesteps(1000)\n",
    "    for t in ddpm_scheduler.timesteps:\n",
    "        timesteps = t.reshape(-1).to('cuda')\n",
    "        pred = surfz_model(_surf_z, timesteps, _surf_pos.to('cuda'), _surf_mask.to('cuda'), None)\n",
    "        _surf_z = ddpm_scheduler.step(pred, t, _surf_z).prev_sample\n",
    "        \n",
    "    _surf_z = _surf_z.squeeze(0)[~_surf_mask.squeeze(0), ...]\n",
    "\n",
    "    # VAE Decoding\n",
    "    with torch.no_grad(): decoded_surf_pos = surf_vae(_surf_z.view(-1, latent_channels, latent_size, latent_size))\n",
    "    pred_img = make_grid(decoded_surf_pos, nrow=6, normalize=True, value_range=(-1,1))\n",
    "\n",
    "    if vis:\n",
    "        fig, ax = plt.subplots(3, 1, figsize=(40, 40))\n",
    "        ax[0].imshow(pred_img[:3, ...].permute(1, 2, 0).detach().cpu().numpy())\n",
    "        ax[1].imshow(pred_img[3:, ...].permute(1, 2, 0).detach().cpu().numpy())\n",
    "        ax[2].imshow(pred_img[-1:, ...].permute(1, 2, 0).detach().cpu().numpy())\n",
    "\n",
    "        ax[0].set_title('Geometry Images')\n",
    "        ax[1].set_title('UV Images')\n",
    "        ax[2].set_title('Mask Images')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.axis('off')\n",
    "                \n",
    "        if output_fp: plt.savefig(output_fp.replace('.pkl', '_geo_img.png'), transparent=True, dpi=72)\n",
    "        else: plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    # plotly visualization\n",
    "    n_surfs = decoded_surf_pos.shape[0]\n",
    "    colormap = plt.cm.rainbow\n",
    "\n",
    "    _surf_bbox = _surf_pos.squeeze(0)[~_surf_mask.squeeze(0), :].detach().cpu().numpy()\n",
    "    _decoded_surf_pos = decoded_surf_pos.permute(0, 2, 3, 1).detach().cpu().numpy()\n",
    "    _surf_ncs_mask = _decoded_surf_pos[..., -1:].reshape(n_surfs, -1) > 0.0\n",
    "    _surf_ncs = _decoded_surf_pos[..., :3].reshape(n_surfs, -1, 3)\n",
    "    _surf_uv_ncs = _decoded_surf_pos[..., 3:5].reshape(n_surfs, -1, 2)\n",
    "\n",
    "    _surf_uv_bbox = _surf_bbox[..., 6:]\n",
    "    _surf_bbox = _surf_bbox[..., :6]\n",
    "\n",
    "    if vis:\n",
    "        colors = [to_hex(colormap(i)) for i in np.linspace(0, 1, n_surfs)]\n",
    "        _surf_wcs = _denormalize_pts(_surf_ncs, _surf_bbox)\n",
    "        # _surf_uv_wcs = _denormalize_pts(_surf_uv_ncs, _surf_uv_bbox)\n",
    "        draw_bbox_geometry(\n",
    "            bboxes = _surf_bbox, \n",
    "            bbox_colors = colors, \n",
    "            points = _surf_wcs, \n",
    "            point_masks = _surf_ncs_mask, \n",
    "            point_colors = colors, \n",
    "            num_point_samples = 5000, \n",
    "            title = caption,\n",
    "            output_fp = output_fp.replace('.pkl', '_pointcloud.png')\n",
    "            )\n",
    "\n",
    "    result = {\n",
    "        'surf_bbox': _surf_bbox,        # (N, 6)\n",
    "        'surf_uv_bbox': _surf_uv_bbox,  # (N, 4)\n",
    "        'surf_ncs': _surf_ncs,          # (N, 256*256, 3)\n",
    "        'surf_uv_ncs': _surf_uv_ncs,    # (N, 256*256, 2)\n",
    "        'surf_mask': _surf_ncs_mask,    # (N, 256*256) => bool\n",
    "        'caption': caption              # str\n",
    "    }\n",
    "\n",
    "    if output_fp: \n",
    "        with open(output_fp, 'wb') as f: pickle.dump(result, f)\n",
    "    \n",
    "    # print('[DONE] save to:', output_fp)\n",
    "    \n",
    "\n",
    "cache_fp = '/data/lry/code/style3d_gen/log/stylexd_vae_surf_256_xyz_uv_mask_unet6_latent_1/cache/vae_e550/encoder_mode/surfpos_validate.pkl'\n",
    "with open(cache_fp, 'rb') as f: data_cache = pickle.load(f)\n",
    "for sample_data_idx in trange(len(data_cache['item_idx'])):\n",
    "    # sample_data_idx = random.randint(0, len(data_cache['item_idx']) - 1)\n",
    "\n",
    "    start_idx, end_idx = data_cache['item_idx'][sample_data_idx]\n",
    "\n",
    "    surf_pos = data_cache['surf_pos'][start_idx:end_idx].to('cuda')\n",
    "    surf_cls = data_cache['surf_cls'][start_idx:end_idx].to('cuda')\n",
    "    caption = data_cache['caption'][sample_data_idx]\n",
    "    \n",
    "    output_fp = os.path.join(output_dir, f'{sample_data_idx:04d}.pkl')\n",
    "    inference_one(surf_pos, surf_cls, caption, output_fp, vis=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5a3321",
   "metadata": {},
   "source": [
    "# Test SurfPos && SurfZ && VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb398019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "\n",
    "import torch\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import to_hex\n",
    "\n",
    "from network import AutoencoderKLFastDecode, SurfZNet\n",
    "from diffusers import DDPMScheduler, PNDMScheduler\n",
    "from utils import randn_tensor\n",
    "from vis import draw_bbox_geometry\n",
    "\n",
    "\n",
    "\n",
    "def _denormalize_pts(pts, bbox):    \n",
    "    pos_dim =  pts.shape[-1]\n",
    "    bbox_min = bbox[..., :pos_dim][:, None, ...]\n",
    "    bbox_max = bbox[..., pos_dim:][:, None, ...]\n",
    "    bbox_scale = np.max(bbox_max - bbox_min, axis=-1, keepdims=True) * 0.5\n",
    "    bbox_offset = (bbox_max + bbox_min) / 2.0\n",
    "    return pts * bbox_scale + bbox_offset\n",
    "\n",
    "\n",
    "vae_model_fp = '/data/lry/code/style3d_gen/log/stylexd_vae_surf_256_xyz_uv_mask_unet6_latent_1/ckpts/vae_e550.pt'\n",
    "surf_pos_model = ''\n",
    "surfz_model_fp = '/data/lry/code/style3d_gen/log/stylexd_surfz_xyzuv_mask_latent1_mode/ckpts/surfz_e150000.pt'\n",
    "\n",
    "# ckpt_fp = '/data/lry/code/dy/checkpoint/6G/ldm/surfz10200.pt'\n",
    "block_dims = [16,32,32,64,64,128]\n",
    "sample_size = 256\n",
    "latent_size = sample_size//(2**(len(block_dims)-1))\n",
    "latent_channels = 1\n",
    "\n",
    "surf_vae = AutoencoderKLFastDecode( in_channels=6,\n",
    "                                    out_channels=6,\n",
    "                                    down_block_types=['DownEncoderBlock2D']*len(block_dims),\n",
    "                                    up_block_types=['UpDecoderBlock2D']*len(block_dims),\n",
    "                                    block_out_channels=block_dims,\n",
    "                                    layers_per_block=2,\n",
    "                                    act_fn='silu',\n",
    "                                    latent_channels=latent_channels,\n",
    "                                    norm_num_groups=8,\n",
    "                                    sample_size=sample_size\n",
    "                                    )\n",
    "surf_vae.load_state_dict(torch.load(vae_model_fp), strict=False)\n",
    "surf_vae.to('cuda').eval()\n",
    "\n",
    "pndm_scheduler = PNDMScheduler(\n",
    "    num_train_timesteps=1000,\n",
    "    beta_schedule='linear',\n",
    "    prediction_type='epsilon',\n",
    "    beta_start=0.0001,\n",
    "    beta_end=0.02,\n",
    ")\n",
    "\n",
    "ddpm_scheduler = DDPMScheduler(\n",
    "    num_train_timesteps=1000,\n",
    "    beta_schedule='linear',\n",
    "    prediction_type='epsilon',\n",
    "    beta_start=0.0001,\n",
    "    beta_end=0.02,\n",
    "    clip_sample=False,\n",
    ")\n",
    "\n",
    "# Load SurfZ Net\n",
    "surfz_model = SurfZNet(\n",
    "    p_dim=10, \n",
    "    z_dim=latent_size**2*latent_channels, \n",
    "    num_heads=12, \n",
    "    num_cf=-1\n",
    "    )\n",
    "surfz_model.load_state_dict(torch.load(surfz_model_fp)['model_state_dict'])\n",
    "surfz_model.to('cuda').eval()\n",
    "\n",
    "output_dir = '/data/lry/code/style3d_gen/generated/surfz_e150000'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def inference_one(surf_pos, surf_cls=None, caption='', output_fp='', vis=False):\n",
    "    n_surfs, n_pads = surf_pos.shape[0], 32-surf_pos.shape[0]\n",
    "    # # pad zero\n",
    "    pad_idx = torch.randperm(n_surfs)\n",
    "    _surf_mask = torch.cat([\n",
    "        torch.zeros(n_surfs, dtype=bool), torch.ones(n_pads, dtype=bool)\n",
    "    ], dim=0)[None, ...]\n",
    "    _surf_pos = torch.cat([\n",
    "        surf_pos[pad_idx, ...], torch.zeros((n_pads, *surf_pos.shape[1:]), dtype=surf_pos.dtype, device=surf_pos.device)\n",
    "    ], dim=0)[None, ...]\n",
    "\n",
    "    # Diffusion Generation\n",
    "    _surf_z = randn_tensor((1, 32, latent_channels*latent_size*latent_size), device='cuda')\n",
    "    ddpm_scheduler.set_timesteps(1000)\n",
    "    for t in ddpm_scheduler.timesteps:\n",
    "        timesteps = t.reshape(-1).to('cuda')\n",
    "        pred = surfz_model(_surf_z, timesteps, _surf_pos.to('cuda'), _surf_mask.to('cuda'), None)\n",
    "        _surf_z = ddpm_scheduler.step(pred, t, _surf_z).prev_sample\n",
    "        \n",
    "    _surf_z = _surf_z.squeeze(0)[~_surf_mask.squeeze(0), ...]\n",
    "\n",
    "    # VAE Decoding\n",
    "    with torch.no_grad(): decoded_surf_pos = surf_vae(_surf_z.view(-1, latent_channels, latent_size, latent_size))\n",
    "    pred_img = make_grid(decoded_surf_pos, nrow=6, normalize=True, value_range=(-1,1))\n",
    "\n",
    "    if vis:\n",
    "        fig, ax = plt.subplots(3, 1, figsize=(40, 40))\n",
    "        ax[0].imshow(pred_img[:3, ...].permute(1, 2, 0).detach().cpu().numpy())\n",
    "        ax[1].imshow(pred_img[3:, ...].permute(1, 2, 0).detach().cpu().numpy())\n",
    "        ax[2].imshow(pred_img[-1:, ...].permute(1, 2, 0).detach().cpu().numpy())\n",
    "\n",
    "        ax[0].set_title('Geometry Images')\n",
    "        ax[1].set_title('UV Images')\n",
    "        ax[2].set_title('Mask Images')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.axis('off')\n",
    "                \n",
    "        if output_fp: plt.savefig(output_fp.replace('.pkl', '_geo_img.png'), transparent=True, dpi=72)\n",
    "        else: plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    # plotly visualization\n",
    "    n_surfs = decoded_surf_pos.shape[0]\n",
    "    colormap = plt.cm.rainbow\n",
    "\n",
    "    _surf_bbox = _surf_pos.squeeze(0)[~_surf_mask.squeeze(0), :].detach().cpu().numpy()\n",
    "    _decoded_surf_pos = decoded_surf_pos.permute(0, 2, 3, 1).detach().cpu().numpy()\n",
    "    _surf_ncs_mask = _decoded_surf_pos[..., -1:].reshape(n_surfs, -1) > 0.0\n",
    "    _surf_ncs = _decoded_surf_pos[..., :3].reshape(n_surfs, -1, 3)\n",
    "    _surf_uv_ncs = _decoded_surf_pos[..., 3:5].reshape(n_surfs, -1, 2)\n",
    "\n",
    "    _surf_uv_bbox = _surf_bbox[..., 6:]\n",
    "    _surf_bbox = _surf_bbox[..., :6]\n",
    "\n",
    "    if vis:\n",
    "        colors = [to_hex(colormap(i)) for i in np.linspace(0, 1, n_surfs)]\n",
    "        _surf_wcs = _denormalize_pts(_surf_ncs, _surf_bbox)\n",
    "        # _surf_uv_wcs = _denormalize_pts(_surf_uv_ncs, _surf_uv_bbox)\n",
    "        draw_bbox_geometry(\n",
    "            bboxes = _surf_bbox, \n",
    "            bbox_colors = colors, \n",
    "            points = _surf_wcs, \n",
    "            point_masks = _surf_ncs_mask, \n",
    "            point_colors = colors, \n",
    "            num_point_samples = 5000, \n",
    "            title = caption,\n",
    "            output_fp = output_fp.replace('.pkl', '_pointcloud.png')\n",
    "            )\n",
    "\n",
    "    result = {\n",
    "        'surf_bbox': _surf_bbox,        # (N, 6)\n",
    "        'surf_uv_bbox': _surf_uv_bbox,  # (N, 4)\n",
    "        'surf_ncs': _surf_ncs,          # (N, 256*256, 3)\n",
    "        'surf_uv_ncs': _surf_uv_ncs,    # (N, 256*256, 2)\n",
    "        'surf_mask': _surf_ncs_mask,    # (N, 256*256) => bool\n",
    "        'caption': caption              # str\n",
    "    }\n",
    "\n",
    "    if output_fp: \n",
    "        with open(output_fp, 'wb') as f: pickle.dump(result, f)\n",
    "    \n",
    "    # print('[DONE] save to:', output_fp)\n",
    "    \n",
    "\n",
    "cache_fp = '/data/lry/code/style3d_gen/log/stylexd_vae_surf_256_xyz_uv_mask_unet6_latent_1/cache/vae_e550/encoder_mode/surfpos_validate.pkl'\n",
    "with open(cache_fp, 'rb') as f: data_cache = pickle.load(f)\n",
    "\n",
    "\n",
    "for sample_data_idx in trange(1100, len(data_cache['item_idx'])):\n",
    "    # sample_data_idx = random.randint(0, len(data_cache['item_idx']) - 1)\n",
    "\n",
    "    start_idx, end_idx = data_cache['item_idx'][sample_data_idx]\n",
    "\n",
    "    surf_pos = data_cache['surf_pos'][start_idx:end_idx].to('cuda')\n",
    "    surf_cls = data_cache['surf_cls'][start_idx:end_idx].to('cuda')\n",
    "    caption = data_cache['caption'][sample_data_idx]\n",
    "    \n",
    "    output_fp = os.path.join(output_dir, f'{sample_data_idx:04d}.pkl')\n",
    "    inference_one(surf_pos, surf_cls, caption, output_fp, vis=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21201bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
