import os
import wandb
from tqdm import tqdm
from glob import glob

from typing import Any, Callable, Dict, List, Optional, Union

import torch
import torch.nn as nn 
from torchvision.utils import make_grid
import torchvision.transforms.functional as F
from diffusers import AutoencoderKL, DDPMScheduler
from src.network import *
from src.utils import get_wandb_logging_meta

# visualization utils
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.express as px

class SurfVAETrainer():
    """ Surface VAE Trainer """
    def __init__(self, args, train_dataset, val_dataset): 
        # Initilize model and load to gpu
        self.iters = 0
        self.epoch = 0
        self.log_dir = args.log_dir
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        self.train_dataset = train_dataset
        self.val_dataset = val_dataset
        self.batch_size = args.batch_size
        
        self.data_fields = args.data_fields

        assert train_dataset.num_channels == val_dataset.num_channels, \
            'Expecting same dimensions for train and val dataset, got %d (train) and %d (val).'%(train_dataset.num_channels, val_dataset.num_channels)
        
        num_channels = train_dataset.num_channels
        sample_size = train_dataset.resolution
        latent_channels = args.latent_channels

        model = AutoencoderKL(
            in_channels=num_channels,
            out_channels=num_channels,
            down_block_types=['DownEncoderBlock2D']*len(args.block_dims),
            up_block_types= ['UpDecoderBlock2D']*len(args.block_dims),
            block_out_channels=args.block_dims,
            layers_per_block=2,
            act_fn='silu',
            latent_channels=latent_channels,
            norm_num_groups=8,
            sample_size=sample_size,
        )
            
        if args.finetune:
            state_dict = torch.load(args.weight)
            if 'model_state_dict' in state_dict: model.load_state_dict(state_dict['model_state_dict'])
            elif 'model' in state_dict: model.load_state_dict(state_dict['model'])
            else: model.load_state_dict(state_dict)
            print('Load SurfZNet checkpoint from %s.'%(args.weight))
            
        self.model = model.to(self.device).train()

        # Initialize optimizer
        self.network_params = list(self.model.parameters())
        self.optimizer = torch.optim.AdamW(
            self.network_params,
            lr=5e-4, 
            weight_decay=1e-5
        )
        self.scaler = torch.cuda.amp.GradScaler()

        # Initialize wandb
        run_id, run_step = get_wandb_logging_meta(os.path.join(args.log_dir, args.expr,'wandb'))
        wandb.init(project='GarmentGen', dir=args.log_dir, name=args.expr, id=run_id, resume='allow')
        self.iters = run_step

        # Initilizer dataloader
        self.train_dataloader = torch.utils.data.DataLoader(self.train_dataset, 
                                                shuffle=True, 
                                                batch_size=self.batch_size,
                                                num_workers=8)
        self.val_dataloader = torch.utils.data.DataLoader(self.val_dataset, 
                                             shuffle=False, 
                                             batch_size=self.batch_size,
                                             num_workers=8)

        self.epoch = self.iters // len(self.train_dataloader)
        return

    
    def train_one_epoch(self):
        """
        Train the model for one epoch
        """
        self.model.train()
        loss_fn = nn.MSELoss()

        progress_bar = tqdm(total=len(self.train_dataloader))
        progress_bar.set_description(f"Epoch {self.epoch}")

        # Train    
        for surf_uv in self.train_dataloader:
                        
            with torch.cuda.amp.autocast():
                surf_uv = surf_uv.to(self.device).permute(0,3,1,2)
                self.optimizer.zero_grad() # zero gradient

                # Pass through VAE
                # Garmage编码得到分布，从分布中采样出Z，Z解码得到Garmage
                posterior = self.model.encode(surf_uv).latent_dist
                z = posterior.sample()      # = posterior.mean + torch.randn_like(posterior.std)*posterior.std
                dec = self.model.decode(z).sample

                # Loss functions
                kl_loss = posterior.kl().mean()  # posterior.kl() 返回当前批次中每个Garmage的KL散度，然后求平均值
                mse_loss = loss_fn(dec, surf_uv)  # 同时计算Garmage编码解码后的误差
                total_loss = mse_loss + 1e-6*kl_loss

                # Update model
                self.scaler.scale(total_loss).backward()
                nn.utils.clip_grad_norm_(self.network_params, max_norm=5.0)  
                self.scaler.step(self.optimizer)
                self.scaler.update()

            # logging
            if self.iters % 10 == 0:
                _z = posterior.mode()
                wandb.log({
                    "loss-mse": mse_loss, "loss-kl": kl_loss, 
                    "z-min": z.min(), "z-max": z.max(), "z-mean": z.mean(), "z-std": z.std(), 
                    "mode-min": _z.min(), "mode-max": _z.max(), "mode-mean": _z.mean(), "mode-std": _z.std() 
                    }, step=self.iters)

            self.iters += 1
            progress_bar.update(1)

        progress_bar.close()
        
        # update train dataset
        self.train_dataset.update()
        self.train_dataloader = torch.utils.data.DataLoader(
            self.train_dataset, shuffle=True, batch_size=self.batch_size, num_workers=8)
        self.epoch += 1 
        
        return 
    

    def test_val(self):
        """
        Test the model on validation set
        """
        print('Running validation...')
        self.model.eval() # set to eval
        total_loss = 0
        total_count = 0
        mse_loss = nn.MSELoss(reduction='none')
        
        val_images = None
        
        with torch.no_grad():
            for surf_uv in self.val_dataloader:
                surf_uv = surf_uv.to(self.device).permute(0,3,1,2) # (N, H, W, C) => (N, C, H, W)
                
                posterior = self.model.encode(surf_uv).latent_dist
                z = posterior.sample()
                dec = self.model.decode(z).sample

                loss = mse_loss(dec, surf_uv).mean((1,2,3)).sum().item()
                total_loss += loss
                total_count += len(surf_uv)
                
                if val_images is None and dec.shape[0] > 16:
                    sample_idx = torch.randperm(dec.shape[0])[:16]
                    val_images = make_grid(dec[sample_idx, ...], nrow=8, normalize=True, value_range=(-1,1))
                    
                    vis_log = {}
                    if 'surf_ncs' in self.data_fields: vis_log['Val-Geo'] = wandb.Image(val_images[:3, ...], caption="Geometry output.")
                    if 'surf_uv_ncs' in self.data_fields: vis_log['Val-UV'] = wandb.Image(val_images[-3:, ...], caption="UV output.")
                    if 'surf_normals' in self.data_fields: vis_log['Val-Normal'] = wandb.Image(val_images[3:6, ...], caption="Normal output.")
                    if 'surf_mask' in self.data_fields: vis_log['Val-Mask'] = wandb.Image(val_images[-1:, ...], caption="Mask output.")                        
                    wandb.log(vis_log, step=self.iters)
    
        mse = total_loss/total_count
        self.model.train() # set to train
        wandb.log({"Val-mse": mse}, step=self.iters)
        
        self.val_dataset.update()
        self.val_dataloader = torch.utils.data.DataLoader(self.val_dataset, 
                                             shuffle=False, 
                                             batch_size=self.batch_size,
                                             num_workers=8)    
        
        return mse
    
    
    def save_model(self):
        ckpt_log_dir = os.path.join(self.log_dir, 'ckpts')
        os.makedirs(ckpt_log_dir, exist_ok=True)
        torch.save(
            self.model.state_dict(), 
            os.path.join(ckpt_log_dir, f'vae_e{self.epoch:04d}.pt'))
        return
    
    
class SurfPosTrainer():
    """ Surface Position Trainer (3D bbox) """
    def __init__(self, args, train_dataset, val_dataset): 
        # Initilize model and load to gpu
        self.iters = 0
        self.epoch = 0
        self.log_dir = args.log_dir
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.bbox_scaled = args.bbox_scaled

        # Initialize text encoder
        if args.text_encoder is not None: self.text_encoder = TextEncoder(args.text_encoder, self.device)
        if args.pointcloud_encoder is not None: self.pointcloud_encoder = PointcloudEncoder(args.pointcloud_encoder, self.device)
        if args.sketch_encoder is not None: self.sketch_encoder = args.sketch_encoder
        assert args.text_encoder is None or args.pointcloud_encoder is None or args.sketch_encoder is None

        if hasattr(self, 'text_encoder'):
            condition_dim = self.text_encoder.text_emb_dim
        elif hasattr(self, 'pointcloud_encoder'):
            condition_dim = self.pointcloud_encoder.pointcloud_emb_dim
        elif args.sketch_encoder is not None:
            if args.sketch_encoder == "LAION2B":
                condition_dim = 1280
            else:
                raise NotImplementedError("args.sketch_encoder name wrong.")
        else:
            condition_dim = -1


        # Initialize network
        self.pos_dim = train_dataset.pos_dim

        model = SurfPosNet(
            p_dim=self.pos_dim * 2,
            condition_dim=condition_dim,
            num_cf=train_dataset.num_classes)

        if args.finetune:
            state_dict = torch.load(args.weight)
            if 'bbox_scaled' in state_dict:
                self.bbox_scaled = train_dataset.bbox_scaled = val_dataset.bbox_scaled = state_dict['bbox_scaled']
            if 'model_state_dict' in state_dict: model.load_state_dict(state_dict['model_state_dict'])
            elif 'model' in state_dict: model.load_state_dict(state_dict['model'])
            else: model.load_state_dict(state_dict)
            print('Load SurfZNet checkpoint from %s.'%(args.weight))
        
        model = nn.DataParallel(model) # distributed training 
        self.model = model.to(self.device).train()

        self.loss_fn = nn.MSELoss()

        # Initialize diffusion scheduler
        self.noise_scheduler = DDPMScheduler(
            num_train_timesteps=1000,
            beta_schedule='linear',
            prediction_type='epsilon',
            beta_start=0.0001,
            beta_end=0.02,
            clip_sample=False,
        )

        # Initialize optimizer
        self.network_params = list(self.model.parameters())
        
        self.optimizer = torch.optim.AdamW(
            self.network_params,
            lr=5e-4,
            betas=(0.95, 0.999),
            weight_decay=1e-6,
            eps=1e-08,
        )

        self.scaler = torch.cuda.amp.GradScaler()

        # # Initialize wandb
        run_id, run_step = get_wandb_logging_meta(os.path.join(args.log_dir, 'wandb'))
        wandb.init(project='GarmentGen', dir=args.log_dir, name=args.expr, id=run_id, resume='allow')
        self.iters = run_step

        # Initialize dataloader
        self.train_dataloader = torch.utils.data.DataLoader(
            train_dataset, shuffle=True, batch_size=args.batch_size, num_workers=16)
        self.val_dataloader = torch.utils.data.DataLoader(
            val_dataset, shuffle=False, batch_size=args.batch_size, num_workers=16)

        self.epoch = self.iters // len(self.train_dataloader)

        return
    
    
    def train_one_epoch(self):
        """
        Train the model for one epoch
        """
        self.model.train()

        progress_bar = tqdm(total=len(self.train_dataloader))
        progress_bar.set_description(f"Epoch {self.epoch}")

        # Train    
        for data in self.train_dataloader:
            with torch.cuda.amp.autocast():
                surfPos, pad_mask, class_label, caption, pointcloud_feature, sketch_feature = data

                surfPos = surfPos.to(self.device)
                class_label = class_label.to(self.device)

                if hasattr(self, 'text_encoder'):
                    condition_emb = self.text_encoder(caption)
                elif hasattr(self, 'pointcloud_encoder'):
                    pointcloud_feature.to(self.device)
                    condition_emb = pointcloud_feature
                elif hasattr(self, 'sketch_encoder'):
                    sketch_feature.to(self.device)
                    condition_emb = sketch_feature
                else:
                    condition_emb = None

                bsz = len(surfPos)
                
                self.optimizer.zero_grad() # zero gradient

                # Add noise
                timesteps = torch.randint(0, self.noise_scheduler.config.num_train_timesteps, (bsz,), device=self.device).long()  # [batch,]
                surfPos_noise = torch.randn(surfPos.shape).to(self.device)  
                surfPos_diffused = self.noise_scheduler.add_noise(surfPos, surfPos_noise, timesteps)

                # Predict noise
                surfPos_pred = self.model(surfPos_diffused, timesteps, class_label, condition_emb, True)
              
                # Compute loss
                total_loss = self.loss_fn(surfPos_pred, surfPos_noise)

                # Update model
                self.scaler.scale(total_loss).backward()
                nn.utils.clip_grad_norm_(self.network_params, max_norm=50.0) # clip gradient
                self.scaler.step(self.optimizer)
                self.scaler.update()

            # logging
            if self.iters % 10 == 0: wandb.log({"loss-noise": total_loss}, step=self.iters)

            self.iters += 1
            progress_bar.update(1)

        progress_bar.close()
        self.epoch += 1 
        return 
    

    def test_val(self):
        """
        Test the model on validation set
        """
        self.model.eval() # set to eval
        total_count = 0
        mse_loss = nn.MSELoss(reduction='none')
        total_loss = [0,0,0,0,0]

        for data in self.val_dataloader:
            surfPos, pad_mask, class_label, caption, pointcloud_feature, sketch_feature = data

            surfPos = surfPos.to(self.device)
            class_label = class_label.to(self.device)

            if hasattr(self, 'text_encoder'):
                condition_emb = self.text_encoder(caption)
            elif hasattr(self, 'pointcloud_encoder'):
                pointcloud_feature.to(self.device)
                condition_emb = pointcloud_feature
            elif hasattr(self, 'sketch_encoder'):
                sketch_feature.to(self.device)
                condition_emb = sketch_feature
            else:
                condition_emb = None

            # text_emb = self.text_encoder(caption) if \
            #     caption and hasattr(self, 'text_encoder') else None
            bsz = len(surfPos)
            total_count += len(surfPos)
            
            val_timesteps = [10,50,100,200,500,1000]
            total_loss = [0]*len(val_timesteps)
            
            vis_batch = torch.randint(0, len(self.val_dataloader), (1,)).item()   
            for idx, step in enumerate(val_timesteps):
                # Evaluate at timestep 
                timesteps = torch.randint(step-1, step, (bsz,), device=self.device).long()  # [batch,]
                surfPos_noise = torch.randn(surfPos.shape).to(self.device)  
                surfPos_diffused = self.noise_scheduler.add_noise(surfPos, surfPos_noise, timesteps)
                
                with torch.no_grad(): pred = self.model(surfPos_diffused, timesteps, class_label, condition_emb)
                
                loss = mse_loss(pred, surfPos_noise).mean((1,2)).sum().item()
                total_loss[idx] += loss

        mse = [loss/total_count for loss in total_loss]
        self.model.train() # set to train
        wandb.log(
            dict([(f"val-{step:04d}", mse[idx]) for idx, step in enumerate(val_timesteps)]), 
            step=self.iters)
        
        return
    
    
    def save_model(self):
        ckpt_log_dir = os.path.join(self.log_dir, 'ckpts')
        os.makedirs(ckpt_log_dir, exist_ok=True)
        torch.save({
            'model_state_dict': self.model.module.state_dict(),
            'bbox_scaled': self.bbox_scaled
        }, os.path.join(ckpt_log_dir, f'surfpos_e{self.epoch:04d}.pt'))
        return


class SurfZTrainer():
    """ Surface Latent Geometry Trainer. """
    def __init__(self, args, train_dataset, val_dataset): 
        
        # Initilize model and load to gpu
        self.iters = 0
        self.epoch = 0
        self.log_dir = args.log_dir
        self.z_scaled = args.z_scaled
        self.bbox_scaled = args.bbox_scaled
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
         
        self.train_dataset = train_dataset
        self.val_dataset = val_dataset
        self.batch_size = args.batch_size
        
        self.pos_dim = self.train_dataset.pos_dim        
        self.num_channels = self.train_dataset.num_channels
        self.sample_size = self.train_dataset.resolution
        self.latent_channels = args.latent_channels
        self.block_dims = args.block_dims

        # Initialize text encoder
        if args.text_encoder is not None: self.text_encoder = TextEncoder(args.text_encoder, self.device)
        if args.pointcloud_encoder is not None: self.pointcloud_encoder = PointcloudEncoder(args.pointcloud_encoder, self.device)
        if args.sketch_encoder is not None: self.sketch_encoder = args.sketch_encoder
        assert args.text_encoder is None or args.pointcloud_encoder is None or args.sketch_encoder is None
        if hasattr(self, 'text_encoder'):
            condition_dim = self.text_encoder.text_emb_dim
        elif hasattr(self, 'pointcloud_encoder'):
            condition_dim = self.pointcloud_encoder.pointcloud_emb_dim
        elif args.sketch_encoder is not None:
            if args.sketch_encoder == "LAION2B":
                condition_dim = 1280
            else:
                raise NotImplementedError("args.sketch_encoder name wrong.")
        else:
            condition_dim = -1

        # Load pretrained surface vae (fast encode version)
        surf_vae_encoder = AutoencoderKLFastEncode(
            in_channels=self.num_channels,
            out_channels=self.num_channels,
            down_block_types=['DownEncoderBlock2D']*len(self.block_dims),
            up_block_types= ['UpDecoderBlock2D']*len(self.block_dims),
            block_out_channels=self.block_dims,
            layers_per_block=2,
            act_fn='silu',
            latent_channels=self.latent_channels,
            norm_num_groups=8,
            sample_size=self.sample_size,
        )
        
        surf_vae_encoder.load_state_dict(torch.load(args.surfvae), strict=False)
        surf_vae_encoder = nn.DataParallel(surf_vae_encoder) # distributed inference 
        self.surf_vae_encoder = surf_vae_encoder.to(self.device).eval()
        
        print('[DONE] Init parallel surface vae encoder.')
        
        train_dataset.init_encoder(self.surf_vae_encoder, self.z_scaled)
        val_dataset.init_encoder(self.surf_vae_encoder, train_dataset.z_scaled)
        if self.z_scaled is None: self.z_scaled = train_dataset.z_scaled
               
        # Initialize network
        model = SurfZNet(
            p_dim=self.pos_dim*2,
            z_dim=(self.sample_size//(2**(len(args.block_dims)-1)))**2 * self.latent_channels,
            num_heads=12,
            condition_dim=condition_dim,
            num_cf=train_dataset.num_classes
            )
        
        if args.finetune:
            state_dict = torch.load(args.weight)
            if 'z_scaled' in state_dict: 
                self.z_scaled = train_dataset.z_scaled = val_dataset.z_scaled = state_dict['z_scaled']
            if 'bbox_scaled' in state_dict:
                self.bbox_scaled = train_dataset.bbox_scaled = val_dataset.bbox_scaled = state_dict['bbox_scaled']
            if 'model_state_dict' in state_dict: model.load_state_dict(state_dict['model_state_dict'])
            elif 'model' in state_dict: model.load_state_dict(state_dict['model'])
            else: model.load_state_dict(state_dict)
            print('Load SurfZNet checkpoint from %s.'%(args.weight))
        
        model = nn.DataParallel(model) # distributed training 
        self.model = model.to(self.device).train()
                
        self.device = self.model.module.parameters().__next__().device

        self.loss_fn = nn.MSELoss()

        # Initialize diffusion scheduler
        self.noise_scheduler = DDPMScheduler(
            num_train_timesteps=1000,
            beta_schedule='linear',
            prediction_type='epsilon',
            beta_start=0.0001,
            beta_end=0.02,
            clip_sample=False,
        )

        # Initialize optimizer
        self.network_params = list(self.model.parameters())
        
        self.optimizer = torch.optim.AdamW(
            self.network_params,
            lr=5e-4,
            betas=(0.95, 0.999),
            weight_decay=1e-6,
            eps=1e-08,
        )

        self.scaler = torch.cuda.amp.GradScaler()

        # Initialize wandb
        run_id, run_step = get_wandb_logging_meta(os.path.join(args.log_dir, 'wandb'))
        wandb.init(project='GarmentGen', dir=args.log_dir, name=args.expr, id=run_id, resume='allow')
        self.iters = run_step

        # Initilizer dataloader
        self.train_dataloader = torch.utils.data.DataLoader(self.train_dataset, 
                                                shuffle=True, 
                                                batch_size=self.batch_size,
                                                num_workers=16)
        self.val_dataloader = torch.utils.data.DataLoader(self.val_dataset, 
                                             shuffle=False, 
                                             batch_size=self.batch_size,
                                             num_workers=16)

        self.epoch = self.iters // len(self.train_dataloader)

        return
    

    def train_one_epoch(self):
        """
        Train the model for one epoch
        """
        self.model.train()

        progress_bar = tqdm(total=len(self.train_dataloader))
        progress_bar.set_description(f"Epoch {self.epoch}")

        # Train    
        for data in self.train_dataloader:
            with torch.cuda.amp.autocast():
                surfPos, surfZ, surf_mask, surf_cls, caption, pointcloud_feature, sketch_feature  = data
                surfPos, surfZ, surf_mask, surf_cls = \
                    surfPos.to(self.device), surfZ.to(self.device), \
                    surf_mask.to(self.device), surf_cls.to(self.device)

                # encode text
                if hasattr(self, 'text_encoder'):
                    condition_emb = self.text_encoder(caption)
                elif hasattr(self, 'pointcloud_encoder'):
                    pointcloud_feature.to(self.device)
                    condition_emb = pointcloud_feature
                elif hasattr(self, 'sketch_encoder'):
                    sketch_feature.to(self.device)
                    condition_emb = sketch_feature
                else:
                    condition_emb = None
                    
                bsz = len(surfPos)
                
                # Augment the surface position (see https://arxiv.org/abs/2106.15282)
                if torch.rand(1) > 0.3:
                    aug_ts = torch.randint(0, 15, (bsz,), device=self.device).long()
                    aug_noise = torch.randn(surfPos.shape).to(self.device)
                    surfPos = self.noise_scheduler.add_noise(surfPos, aug_noise, aug_ts)

                surfZ = surfZ * self.z_scaled
                self.optimizer.zero_grad() # zero gradient

                # Add noise
                timesteps = torch.randint(0, self.noise_scheduler.config.num_train_timesteps, (bsz,), device=self.device).long()  # [batch,]
                surfZ_noise = torch.randn(surfZ.shape).to(self.device)  
                surfZ_diffused = self.noise_scheduler.add_noise(surfZ, surfZ_noise, timesteps)
                
                # Predict noise
                surfZ_pred = self.model(surfZ_diffused, timesteps, surfPos, surf_mask, surf_cls, condition_emb, is_train=True)

                # Loss
                total_loss = self.loss_fn(surfZ_pred[~surf_mask], surfZ_noise[~surf_mask])        
             
                # Update model
                self.scaler.scale(total_loss).backward()
                nn.utils.clip_grad_norm_(self.network_params, max_norm=50.0) # clip gradient
                self.scaler.step(self.optimizer)
                self.scaler.update()

            # logging
            if self.iters % 10 == 0:
                wandb.log({
                    "loss-noise": total_loss, "surfz-min": surfZ[~surf_mask].min(), 
                    'z_scaled': self.z_scaled,
                    "surfz-max": surfZ[~surf_mask].max(), "surfz-std": surfZ[~surf_mask].std(), 
                    "surf_mask-min": surf_mask.sum(dim=1).min(), "surf_mask-max": surf_mask.sum(dim=1).max(), 
                    "surfZ_pred-min": surfZ_pred[~surf_mask].min(), 'surfz_pred-max': surfZ_pred[~surf_mask].max()
                    }, step=self.iters)

            self.iters += 1
            progress_bar.update(1)

        progress_bar.close()
        # update train dataset
        if hasattr(self.train_dataset, 'data_chunks') and len(self.train_dataset.data_chunks) > 1:
            print('Updating train data chunks...')
            self.train_dataset.update()        
            self.train_dataloader = torch.utils.data.DataLoader(
                self.train_dataset, shuffle=True, 
                batch_size=self.batch_size, num_workers=16)
        
        self.epoch += 1 
        return 
    

    def test_val(self):
        """
        Test the model on validation set
        """
        self.model.eval() # set to eval
        total_count = 0
        mse_loss = nn.MSELoss(reduction='none')

        progress_bar = tqdm(total=len(self.val_dataloader))
        progress_bar.set_description(f"Testing")

        val_timesteps = [10,50,100,200,500,1000]
        total_loss = [0]*len(val_timesteps)

        vis_batch = torch.randint(0, len(self.val_dataloader), (1,)).item()        
        for batch_idx, data in enumerate(self.val_dataloader):
            surfPos, surfZ, surf_mask, surf_cls, caption, pointcloud_feature, sketch_feature  = data
            surfPos, surfZ, surf_mask, surf_cls = \
                surfPos.to(self.device), surfZ.to(self.device), \
                surf_mask.to(self.device), surf_cls.to(self.device)

            # encode text
            if hasattr(self, 'text_encoder'):
                condition_emb = self.text_encoder(caption)
            elif hasattr(self, 'pointcloud_encoder'):
                pointcloud_feature.to(self.device)
                condition_emb = pointcloud_feature
            elif hasattr(self, 'sketch_encoder'):
                sketch_feature.to(self.device)
                condition_emb = sketch_feature
            else:
                condition_emb = None

            bsz = len(surfPos)
                        
            tokens = surfZ = surfZ * self.z_scaled    

            total_count += len(surfPos)
            
            for idx, step in enumerate(val_timesteps):
                # Evaluate at timestep 
                timesteps = torch.randint(step-1, step, (bsz,), device=self.device).long()  # [batch,]
                noise = torch.randn(tokens.shape).to(self.device)  
                diffused = self.noise_scheduler.add_noise(tokens, noise, timesteps)
                
                with torch.no_grad(): pred = self.model(diffused, timesteps, surfPos, surf_mask, surf_cls, condition_emb)
                    
                loss = mse_loss(pred[~surf_mask], noise[~surf_mask]).mean(-1).sum().item()
                total_loss[idx] += loss

            progress_bar.update(1)
        progress_bar.close()

        mse = [loss/total_count for loss in total_loss]
        self.model.train() # set to train
        wandb.log(dict([(f"val-{step:04d}", mse[idx]) for idx, step in enumerate(val_timesteps)]), step=self.iters)
        
        if hasattr(self.val_dataset, 'data_chunks') and len(self.val_dataset.data_chunks) > 1:
            self.val_dataset.update()
            self.val_dataloader = torch.utils.data.DataLoader(
                self.val_dataset, shuffle=False, 
                batch_size=self.batch_size, num_workers=16)
        return


    def save_model(self):
        ckpt_log_dir = os.path.join(self.log_dir, 'ckpts')
        os.makedirs(ckpt_log_dir, exist_ok=True)        
        torch.save(
            {
                'model_state_dict': self.model.module.state_dict(),
                'z_scaled': self.z_scaled,
                'bbox_scaled': self.bbox_scaled
            }, 
            os.path.join(ckpt_log_dir, f'surfz_e{self.epoch:04d}.pt'))
        return
    