{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Boundary Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import cv2\n",
    "\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def _to_o3d_pc(xyz: np.ndarray, color=None):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(xyz)\n",
    "    \n",
    "    print('[_to_o3d_pc] color: ', pcd.points)\n",
    "        \n",
    "    if color is not None:\n",
    "        if len(color) != len(xyz): \n",
    "            color = np.array(color)[None].repeat(len(xyz), axis=0)\n",
    "        pcd.colors = o3d.utility.Vector3dVector(color)\n",
    "    else:\n",
    "        pcd.colors = o3d.utility.Vector3dVector(0.771 * np.ones_like(xyz))\n",
    "\n",
    "    return pcd\n",
    "\n",
    "\n",
    "def _pad_arr(arr, pad_size=10):\n",
    "    return np.pad(\n",
    "        arr, \n",
    "        ((0, 0), (pad_size, pad_size), (pad_size, pad_size), (0, 0)),   # pad size to each dimension, require tensor to have size (H,W, C)\n",
    "        mode='constant', \n",
    "        constant_values=0)\n",
    "\n",
    "\n",
    "def resample_boundary(points, delta, outlier_thresh=0.05):\n",
    "\n",
    "    points = np.asarray(points)\n",
    "    \n",
    "    # remove outliers\n",
    "    deltas_prev = np.linalg.norm(points - np.roll(points, 1, axis=0), axis=1)\n",
    "    deltas_next = np.linalg.norm(points - np.roll(points, -1, axis=0), axis=1)    \n",
    "        \n",
    "    valid_pts = np.logical_and(deltas_prev < outlier_thresh, deltas_next < outlier_thresh)\n",
    "    points = points[valid_pts, :]\n",
    "        \n",
    "    # Compute distances between consecutive points\n",
    "    points = np.vstack([points, points[0]])  # Close the boundary\n",
    "    deltas = np.linalg.norm(np.diff(points, axis=0), axis=1)\n",
    "    \n",
    "    # Compute cumulative arc length\n",
    "    arc_lengths = np.insert(np.cumsum(deltas), 0, 0)\n",
    "\n",
    "    # Total length of the boundary\n",
    "    total_length = arc_lengths[-1]\n",
    "\n",
    "    # Number of new points\n",
    "    num_points = int(np.ceil(total_length / delta)) + 1\n",
    "\n",
    "    # New equally spaced arc lengths\n",
    "    new_arc_lengths = np.linspace(0, total_length, num=num_points)\n",
    "\n",
    "    # Interpolate to find new points\n",
    "    new_points = np.zeros((num_points, 3))\n",
    "    for i in range(3):  # For x, y, z coordinates\n",
    "        new_points[:, i] = np.interp(new_arc_lengths, arc_lengths, points[:, i])\n",
    "\n",
    "    return new_points\n",
    "\n",
    "\n",
    "# load data\n",
    "mask_fp = \"..\\\\resources\\\\examples\\\\breps\\\\data\\\\mask\\\\mask_8.pkl\"\n",
    "geo_fp = mask_fp.replace('mask', 'xyz')\n",
    "with open(geo_fp, 'rb') as f: geo_orig = pickle.load(f)\n",
    "with open(mask_fp, 'rb') as f: mask = pickle.load(f)\n",
    "\n",
    "geo_orig = _pad_arr(geo_orig, pad_size=5)\n",
    "mask = _pad_arr(mask, pad_size=5)\n",
    "\n",
    "# visualization buffers\n",
    "surf_points = []\n",
    "surf_colors = []\n",
    "boundary_points = []\n",
    "boundary_point_colors = []\n",
    "\n",
    "# process data\n",
    "for s_idx in range(mask.shape[0]):\n",
    "    \n",
    "    geo_dist = np.linalg.norm(geo_orig[s_idx], axis=-1)\n",
    "    if geo_dist.min() < 1e-6 and geo_dist.max() < 1e-6: continue\n",
    "        \n",
    "    valid_pts = np.where(mask[s_idx, :, :, 0] > 0.5)    \n",
    "    \n",
    "    valid_pts = geo_orig[s_idx, valid_pts[0], valid_pts[1], :]    \n",
    "    valid_pts = valid_pts[np.random.randint(0, valid_pts.shape[0], 1000), :]\n",
    "    surf_points.append(valid_pts)\n",
    "    surf_colors.append(np.zeros_like(valid_pts) + 0.5)\n",
    "    \n",
    "    # erode mask image \n",
    "    mask_img = (mask[s_idx] * 255.0).astype(np.uint8) \n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3)) \n",
    "    mask_img = cv2.erode(mask_img, kernel, iterations=1)\n",
    "    mask_img[mask_img >= 150] = 255\n",
    "    mask_img[mask_img < 150] = 0 \n",
    "    \n",
    "    # extract contours from mask image\n",
    "    _, thresh = cv2.threshold(mask_img, 128, 255, cv2.THRESH_BINARY)        \n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    contour_pts = [np.squeeze(contour, axis=1) for contour in contours if contour.shape[0] > 16]\n",
    "\n",
    "    for contour in contours:\n",
    "        if contour.shape[0] < 16: continue  # custom threshold to remove small contours\n",
    "        contour_pts = np.squeeze(contour, axis=1)\n",
    "    \n",
    "        # extract boundary points\n",
    "        geo_arr = geo_orig[s_idx]\n",
    "        geo_sample_pts = geo_arr[contour_pts[:, 1], contour_pts[:, 0], :]    \n",
    "        geo_sample_pts = geo_sample_pts[np.linalg.norm(geo_sample_pts, axis=-1) > 0.01, :]\n",
    "        \n",
    "        # resample boundary points\n",
    "        geo_sample_pts = resample_boundary(geo_sample_pts, 0.01, outlier_thresh=0.1)\n",
    "\n",
    "        # save for visualization\n",
    "        cmap = mpl.colormaps['rainbow']\n",
    "        boundary_points.append(geo_sample_pts)\n",
    "        boundary_point_colors.append(cmap(np.linspace(0, 1, len(geo_sample_pts)))[:, :3])\n",
    "            \n",
    "\n",
    "###################### visualization ########################\n",
    "boundary_points = np.concatenate(boundary_points, axis=0).astype(np.float32)\n",
    "boundary_point_colors = np.concatenate(boundary_point_colors, axis=0)\n",
    "\n",
    "# filtering points that are too close to origin\n",
    "close_to_origin = np.linalg.norm(boundary_points, axis=1) > 0.001\n",
    "boundary_points = boundary_points[close_to_origin, :]\n",
    "boundary_point_colors = boundary_point_colors[close_to_origin, :]\n",
    "boundary_pcd = _to_o3d_pc(boundary_points, boundary_point_colors)\n",
    "\n",
    "surf_points = np.concatenate(surf_points, axis=0).astype(np.float32)\n",
    "surf_pcd = _to_o3d_pc(surf_points)    \n",
    "            \n",
    "mesh_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=1.0, origin=[0., 0., 0.])\n",
    "o3d.visualization.draw_geometries([\n",
    "    mesh_frame, \n",
    "    boundary_pcd, \n",
    "    # surf_pcd\n",
    "    ])\n",
    "\n",
    "# o3d.visualization.draw_geometries([\n",
    "#     mesh_frame, \n",
    "#     boundary_pcd, \n",
    "#     surf_pcd\n",
    "#     ])\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SXD Triangulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import einops\n",
    "import skimage\n",
    "\n",
    "import open3d as o3d\n",
    "\n",
    "\n",
    "def _pad_arr(arr, pad_size=10):\n",
    "    return np.pad(\n",
    "        arr, \n",
    "        ((pad_size, pad_size), (pad_size, pad_size), (0, 0)),   # pad size to each dimension, require tensor to have size (H,W, C)\n",
    "        mode='constant', \n",
    "        constant_values=0)\n",
    "\n",
    "def _to_o3d_mesh(verts: np.ndarray, faces: np.ndarray, color=None):\n",
    "    verts = o3d.utility.Vector3dVector(verts)\n",
    "    faces = o3d.utility.Vector3iVector(faces)\n",
    "    mesh = o3d.geometry.TriangleMesh(verts, faces)\n",
    "        \n",
    "    if color is not None:\n",
    "        if len(color) != len(verts): \n",
    "            color = np.array(color)[None].repeat(len(verts), axis=0)\n",
    "        mesh.vertex_colors = o3d.utility.Vector3dVector(color)   \n",
    "        \n",
    "    return mesh\n",
    "\n",
    "\n",
    "def _to_o3d_pc(xyz: np.ndarray, color=None):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(xyz)\n",
    "    \n",
    "    print('[_to_o3d_pc] color: ', pcd.points)\n",
    "        \n",
    "    if color is not None:\n",
    "        if len(color) != len(xyz): \n",
    "            color = np.array(color)[None].repeat(len(xyz), axis=0)\n",
    "        pcd.colors = o3d.utility.Vector3dVector(color)\n",
    "\n",
    "    return pcd\n",
    "\n",
    "\n",
    "def _make_grid(bb_min=[0,0,0], bb_max=[1,1,1], shape=[10,10,10], \n",
    "            mode='on', flatten=True, indexing=\"ij\"):\n",
    "    \"\"\" Make a grid of coordinates\n",
    "\n",
    "    Args:\n",
    "        bb_min (list or np.array): least coordinate for each dimension\n",
    "        bb_max (list or np.array): maximum coordinate for each dimension\n",
    "        shape (list or int): list of coordinate number along each dimension. If it is an int, the number\n",
    "                            same for all dimensions\n",
    "        mode (str, optional): 'on' to have vertices lying on the boundary and \n",
    "                              'in' for keeping vertices and its cell inside of the boundary\n",
    "                              same as align_corners=True and align_corners=False\n",
    "        flatten (bool, optional): Return as list of points or as a grid. Defaults to True.\n",
    "        indexing ([\"ij\" or \"xy\"]): default to \"xy\", see https://numpy.org/doc/stable/reference/generated/numpy.meshgrid.html\n",
    "\n",
    "    Returns:\n",
    "        np.array: return coordinates (XxYxZxD if flatten==False, X*Y*ZxD if flatten==True.\n",
    "    \"\"\"    \n",
    "    coords=[]\n",
    "    bb_min = np.array(bb_min)\n",
    "    bb_max = np.array(bb_max)\n",
    "    if type(shape) is int:\n",
    "        shape = np.array([shape]*bb_min.shape[0])\n",
    "    for i,si in enumerate(shape):\n",
    "        if mode=='on':\n",
    "            coord = np.linspace(bb_min[i], bb_max[i], si)\n",
    "        elif mode=='in':\n",
    "            offset = (bb_max[i]-bb_min[i])/2./si\n",
    "            # 2*si*w=bmax-bmin\n",
    "            # w = (bmax-bmin)/2/si\n",
    "            # start, end = bmax+w, bmin-w\n",
    "            coord = np.linspace(bb_min[i]+offset,bb_max[i]-offset, si)\n",
    "        coords.append( coord )\n",
    "    grid = np.stack(np.meshgrid(*coords,sparse=False, indexing=indexing), axis=-1)\n",
    "    if flatten==True:\n",
    "        grid = grid.reshape(-1,grid.shape[-1])\n",
    "    return grid\n",
    "\n",
    "\n",
    "def _prune_unused_vertices(vert, face):\n",
    "    # Identify all unique vertex indices used in face\n",
    "    unique_vert_ind = np.unique(face)\n",
    "    mapper = np.zeros(vert.shape[0], dtype=int)\n",
    "    mapper[unique_vert_ind] = np.arange(unique_vert_ind.shape[0])\n",
    "    new_face = mapper[face]\n",
    "    # Create the new vertices array using only the used vertices\n",
    "    new_vert = vert[unique_vert_ind]\n",
    "    \n",
    "    return new_vert, new_face, unique_vert_ind\n",
    "\n",
    "\n",
    "def _downsample_sparse_pooling(omg, factor=4, anti_aliasing=False, visualize=False):\n",
    "    \"\"\" downsample input array with sparse pooling\n",
    "    Args:\n",
    "        omg: np.ndarray, (H, W, 4), omage tensor\n",
    "        factor: int, downsample factor\n",
    "        anti_aliasing: bool, whether to use anti_aliasing\n",
    "        visualize: bool, whether to visualize the result\n",
    "    Returns:\n",
    "        dict, containing 'omg_down_star', 'omg_down', 'sov', 'edge_occ_down'\n",
    "        'omg_down_star': np.ndarray, downsampled omg with edge snapping\n",
    "        'omg_down': np.ndarray, downsampled omg without edge snapping\n",
    "        'sov': np.ndarray, occupancy map with snapped boundaries highlighted\n",
    "        'edge_occ_down': np.ndarray, edge occupancy map\n",
    "    \"\"\"\n",
    "    # assuming omg is 1024 x 1024\n",
    "    occ = omg[..., 3]>=.5\n",
    "    eroded_mask = scipy.ndimage.binary_erosion(occ, structure=np.ones((3,3))) # sqaure strucure is needed to get the corners\n",
    "    edge_occ = ~eroded_mask & occ\n",
    "    edge_omg = omg.copy()\n",
    "    edge_omg[edge_occ==0] = -1.\n",
    "    \n",
    "    edge_occ_patches = einops.rearrange(edge_occ, '(h1 h2) (w1 w2) -> h1 w1 h2 w2', h2=factor, w2=factor)\n",
    "    edge_occ_down = edge_occ_patches.max(axis=-1).max(axis=-1)\n",
    "    eod_0_count  = (edge_occ_patches==0).sum(axis=-1).sum(axis=-1)\n",
    "    eod_1_count  = (edge_occ_patches==1).sum(axis=-1).sum(axis=-1)\n",
    "    edge_omg_patches = einops.rearrange(edge_omg, '(h1 h2) (w1 w2) c-> h1 w1 h2 w2 c', h2=factor, w2=factor)\n",
    "    edge_omg_down = edge_omg_patches.sum(axis=-2).sum(axis=-2) + eod_0_count[...,None]\n",
    "    edge_omg_down = np.divide(edge_omg_down, eod_1_count[...,None], out=np.zeros_like(edge_omg_down), where=eod_1_count[...,None]!=0)\n",
    "\n",
    "    omg_down = skimage.transform.resize(omg, (omg.shape[0]//factor,)*2, order=0, preserve_range=False, anti_aliasing=anti_aliasing)\n",
    "    \n",
    "    omg_down_star = edge_omg_down * (edge_occ_down[...,None]) + omg_down * (1-edge_occ_down[...,None])\n",
    "    star_occ = (omg_down[...,3] >= .5) | edge_occ_down\n",
    "    \n",
    "    sov = (omg_down[...,3] >= .5) # for visualizaton\n",
    "    sov = sov * .5 + edge_occ_down.astype(float)\n",
    "    sov[sov>=1.] = 1.\n",
    "\n",
    "    return dict(omg_down_star=omg_down_star, omg_down=omg_down,\n",
    "            sov=sov, edge_occ_down=edge_occ_down, edge_occ=edge_occ)\n",
    "\n",
    "\n",
    "def meshing_uv_map(occupancy):\n",
    "    occ = occupancy.astype(bool)\n",
    "    pixel_index = np.arange(occ.size).reshape(occ.shape)\n",
    "\n",
    "    # Determine triangles' vertices\n",
    "    is_tri_vert = occ & np.roll(occ, shift=-1, axis=0) & np.roll(occ, shift=-1, axis=1)\n",
    "    verta = pixel_index\n",
    "    vertb = np.roll(pixel_index, shift=-1, axis=1)\n",
    "    vertc = np.roll(pixel_index, shift=-1, axis=0)\n",
    "    face0 = np.stack([verta[is_tri_vert], vertb[is_tri_vert], vertc[is_tri_vert]], axis=1)\n",
    "    \n",
    "    # Determine the second set of triangles' vertices\n",
    "    is_tri_vert = occ & np.roll(occ, shift=1, axis=0) & np.roll(occ, shift=1, axis=1)\n",
    "    verta = pixel_index\n",
    "    vertb = np.roll(pixel_index, shift=1, axis=1)\n",
    "    vertc = np.roll(pixel_index, shift=1, axis=0)\n",
    "    face1 = np.stack([verta[is_tri_vert], vertb[is_tri_vert], vertc[is_tri_vert]], axis=1)\n",
    "    \n",
    "    # Combine the two sets of faces\n",
    "    face = np.concatenate([face0, face1], axis=0)\n",
    "\n",
    "    return face\n",
    "\n",
    "\n",
    "def grid_triangulation(\n",
    "    occ, vert, \n",
    "    normal=None, \n",
    "    color=None, \n",
    "    prune_verts=True, \n",
    "    return_o3d_mesh=False,\n",
    "    return_boundary_verts=False):\n",
    "    \"\"\" Turn an omage into a mesh.\n",
    "    Args:\n",
    "        occ: np.ndarray of shape (H, W, 1) representing the occupancy map.\n",
    "        vert: np.ndarray of shape (H, W, 3) representing the 3D position of each vertex.\n",
    "        normal: np.ndarray of shape (H, W, 3) representing the normal.\n",
    "        return_uv: bool, whether to return uv as well.\n",
    "        prune_verts: bool, whether to remove unused vertices to reduce size.\n",
    "    \"\"\"    \n",
    "    occ = _pad_arr(occ)\n",
    "    vert = _pad_arr(vert)\n",
    "    normal = _pad_arr(normal) if normal is not None else None\n",
    "    \n",
    "    # Generate pixel indices array\n",
    "    vert         = vert.reshape(-1, 3)\n",
    "    normal       = normal.reshape(-1, 3) if normal is not None else None\n",
    "    \n",
    "    face = meshing_uv_map(occ)\n",
    "    if face.shape[0] == 0: # no face, return empty mesh\n",
    "        meshing_ret = dict( vert = np.zeros((0,3)), face = np.zeros((0,3)).astype(int), uv = np.zeros((0,2)))\n",
    "        return meshing_ret\n",
    "\n",
    "    # flip faces with inconsistent objnormal vs face normal\n",
    "    if normal is not None:\n",
    "        face_normal = np.cross(vert[face[:,1]] - vert[face[:,0]], vert[face[:,2]] - vert[face[:,0]])\n",
    "        flip_mask = np.einsum('ij,ij->i', face_normal, normal[face[:,0]]) < 0\n",
    "        face[flip_mask] = face[flip_mask][:,[0,2,1]]\n",
    "    \n",
    "    uv = _make_grid([0,0], [1,1], shape=(occ.shape[0], occ.shape[1]), mode='on')\n",
    "    uv[..., [0,1]] = uv[..., [1,0]] # swap x, y to match the image coordinate system\n",
    "    \n",
    "    \n",
    "    # TODO: snap\n",
    "    \n",
    "    \n",
    "    meshing_ret=dict( vert=vert, face=face, uv=uv)\n",
    "\n",
    "    if prune_verts:\n",
    "        vert, face, unique_vert_ind = _prune_unused_vertices(vert, face)\n",
    "        uv = uv[unique_vert_ind]\n",
    "        for key in meshing_ret:\n",
    "            if key not in ['vert', 'face', 'uv']:\n",
    "                print(key, meshing_ret[key].shape)\n",
    "                meshing_ret[key] = meshing_ret[key][unique_vert_ind]\n",
    "        meshing_ret['vert'], meshing_ret['face'], meshing_ret['uv'] = vert, face, uv\n",
    "        if color is not None:\n",
    "            meshing_ret['color'] = color[unique_vert_ind]\n",
    "        \n",
    "    if return_o3d_mesh:\n",
    "        return _to_o3d_mesh(\n",
    "            meshing_ret['vert'], \n",
    "            meshing_ret['face'], \n",
    "            color=color if color is not None else np.random.rand(3))\n",
    "        \n",
    "    if return_boundary_verts: pass\n",
    "        \n",
    "    return meshing_ret\n",
    "\n",
    "\n",
    "# data_dir = \"E:\\\\lry\\\\code\\\\style3d_gen\\\\resources\\\\examples\\\\outputs_2\"\n",
    "data_dir = \"E:\\\\lry\\\\data\\\\AIGP\\\\demo_v2\\\\Q2\\\\brep_reso_1024\"\n",
    "\n",
    "for idx in range(1,6):\n",
    "    \n",
    "    with open(os.path.join(data_dir, '%05d.pkl'%(idx)), 'rb') as f: data = pickle.load(f)\n",
    "    position = data['surf_wcs']\n",
    "    occ = data['surf_mask']\n",
    "    \n",
    "    # with open(os.path.join(data_dir, 'position', 'xyz_%d.pkl'%(idx)), 'rb') as f: position = pickle.load(f)\n",
    "    # with open(os.path.join(data_dir, 'occ', 'mask_%d.pkl'%(idx)), 'rb') as f: occ = pickle.load(f)\n",
    "    # occ = occ[:, 0, :, :][..., None] \n",
    "    # print('*** occ: ', occ.shape, occ.min(), occ.max(), occ.mean())\n",
    "\n",
    "    meshes = []\n",
    "    boundary_verts = []\n",
    "\n",
    "    for s_idx in range(position.shape[0]):        \n",
    "        # OPTION 1 : grid triangulation        \n",
    "        mesh_ret = grid_triangulation(\n",
    "            occ[s_idx] > 0.85,\n",
    "            position[s_idx][..., :3],\n",
    "            return_o3d_mesh=True\n",
    "        )\n",
    "        meshes.append(mesh_ret)\n",
    "        \n",
    "        # # OPTION 2: del triangulation\n",
    "        # coords = np.argwhere(occ[s_idx] > 0.85)\n",
    "        # plt.imshow(occ[s_idx], cmap='gray')\n",
    "        # plt.scatter(coords[:, 1], coords[:, 0])\n",
    "        # print(coords.shape, coords[0])\n",
    "        # break\n",
    "        \n",
    "        # print(\"*** \", s_idx, mesh_ret['vert'].shape, mesh_ret['vert'].dtype, mesh_ret['face'].shape,  mesh_ret['face'].dtype)\n",
    "        # meshes.append(mesh_ret)\n",
    "        # verts = o3d.utility.Vector3dVector(mesh_ret['vert'])\n",
    "        # faces = o3d.utility.Vector3iVector(mesh_ret['face'])\n",
    "        # meshes.append(_to_o3d_mesh(mesh_ret['vert'], mesh_ret['face'], color=np.random.rand(3)))\n",
    "\n",
    "    # for mesh in meshes:\n",
    "    #     # calculate boundary facets\n",
    "    #     pass\n",
    "\n",
    "    # o3d.visualization.draw_geometries(meshes)\n",
    "    o3d.visualization.draw_geometries(meshes, mesh_show_wireframe=True)\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anno_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
